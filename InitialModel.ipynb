{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-04T19:10:27.421471Z",
     "start_time": "2025-06-04T19:10:18.403169Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from transformers import pipeline\n",
    "\n",
    "# https://huggingface.co/mental/mental-roberta-base\n",
    "#or\n",
    "# https://huggingface.co/mental/mental-bert-base-uncased -- USED THIS\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "MODEL = \"mental/mental-bert-base-uncased\"\n",
    "SampleSize = 500\n",
    "\n",
    "DATA_CSV_PATH = 'dataset/Combined Data 2.csv'\n",
    "\n",
    "TEXT_COLUMN = 'statement'\n",
    "LABEL_COLUMN = 'status'\n",
    "\n",
    "LABELS = ['Anxiety', 'Bipolar', 'Stress', 'Depression', 'Normal', 'Personality disorder', 'Suicidal']\n",
    "NUM_LABELS = len(LABELS)\n",
    "label_to_id = {label: i for i, label in enumerate(LABELS)}\n",
    "id_to_label = {i: label for i, label in enumerate(LABELS)}\n",
    "\n",
    "TRAINING_ARGS = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loading and Preparing Data\n",
   "id": "c2c1e983f1345f2f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T19:10:27.698907Z",
     "start_time": "2025-06-04T19:10:27.430898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Loading data from: {DATA_CSV_PATH}\")\n",
    "df_data = pd.read_csv(DATA_CSV_PATH)\n",
    "df_data = df_data.sample(SampleSize)\n",
    "print(\"Original DataFrame head:\")\n",
    "print(df_data.head())\n",
    "print(f\"Original DataFrame shape: {df_data.shape}\")\n",
    "\n",
    "df_data.dropna(subset=[TEXT_COLUMN, LABEL_COLUMN], inplace=True)\n",
    "df_data = df_data[df_data[LABEL_COLUMN].isin(LABELS)]\n",
    "df_data[TEXT_COLUMN] = df_data[TEXT_COLUMN].astype(str).str.strip()\n",
    "df_data = df_data[df_data[TEXT_COLUMN].str.len() > 0]\n",
    "\n",
    "\n",
    "print(f\"\\nDataFrame shape after cleaning: {df_data.shape}\")\n",
    "if df_data.empty:\n",
    "    print(\"Error: No data left after cleaning. Check your CSV and column names.\")\n",
    "    exit()\n",
    "\n",
    "df_data['labels'] = df_data[LABEL_COLUMN].map(label_to_id)\n",
    "if df_data['labels'].isnull().any():\n",
    "    print(\"Error: Some labels in your CSV did not match the defined LABELS. Check for typos.\")\n",
    "    print(\"Unique labels in CSV:\", df_data[LABEL_COLUMN].unique())\n",
    "    print(\"Defined LABELS:\", LABELS)\n",
    "    exit()\n",
    "\n",
    "train_df, eval_df = train_test_split(df_data, test_size=0.2, random_state=42, stratify=df_data['labels'])\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df[[TEXT_COLUMN, 'labels']])\n",
    "eval_dataset = Dataset.from_pandas(eval_df[[TEXT_COLUMN, 'labels']])\n",
    "\n",
    "print(f\"\\nTraining data samples: {len(train_dataset)}\")\n",
    "print(f\"Evaluation data samples: {len(eval_dataset)}\")\n",
    "print(\"First training example:\", train_dataset[0])"
   ],
   "id": "21607fb027bc4088",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: dataset/Combined Data 2.csv\n",
      "Original DataFrame head:\n",
      "       Unnamed: 0                                          statement  \\\n",
      "26087       26087  I lost so much in such a short amount of timeM...   \n",
      "6937         6937                                       Juan_Sergovy   \n",
      "37140       37140  my wife: on his will it says he's left all his...   \n",
      "16279       16279  I am 21 now. Its really unfortunate but I have...   \n",
      "27668       27668  Things with my foster parents were reaching a ...   \n",
      "\n",
      "           status  \n",
      "26087    Suicidal  \n",
      "6937       Normal  \n",
      "37140    Suicidal  \n",
      "16279  Depression  \n",
      "27668      Normal  \n",
      "Original DataFrame shape: (500, 3)\n",
      "\n",
      "DataFrame shape after cleaning: (491, 3)\n",
      "\n",
      "Training data samples: 392\n",
      "Evaluation data samples: 99\n",
      "First training example: {'statement': 'Why you would not want to live. Is it really that difficult to see that the combination of being 5ft tall, ugly, having a 4incher, being incompetent, weak, stupid, no fun and depressing to be around is why I do not feel like living. I am never going to amount to anything, I am hopeless and useless, I am never going to be wanted or desired. I feel lethargic and just want to sleep an endless sleep. Is it really that difficult to understand. Is it really that bad of a reason. Is it really that hard to imagine?', 'labels': 6, '__index_level_0__': 9185}\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tokenizer and Model for Fine-tuning\n",
   "id": "87feeaeef724bc9b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T19:10:28.941120Z",
     "start_time": "2025-06-04T19:10:27.942053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"\\nLoading tokenizer and model '{MODEL}' for fine-tuning...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL,\n",
    "    num_labels=NUM_LABELS,\n",
    "    id2label=id_to_label,\n",
    "    label2id=label_to_id\n",
    ")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[TEXT_COLUMN], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_eval_dataset = eval_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "tokenized_train_dataset.set_format(\"torch\", columns=['input_ids', 'attention_mask', 'labels'])\n",
    "tokenized_eval_dataset.set_format(\"torch\", columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "if '__index_level_0__' in tokenized_train_dataset.column_names:\n",
    "    tokenized_train_dataset = tokenized_train_dataset.remove_columns(['__index_level_0__'])\n",
    "if '__index_level_0__' in tokenized_eval_dataset.column_names:\n",
    "    tokenized_eval_dataset = tokenized_eval_dataset.remove_columns(['__index_level_0__'])\n"
   ],
   "id": "9b7e1ab382d15fd5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading tokenizer and model 'mental/mental-bert-base-uncased' for fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at mental/mental-bert-base-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/392 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "492d5fb5bc9b4ccfb6848d4d38a0194e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/99 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dfb47ae98c414433be916543072352c8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Metrics and Trainer",
   "id": "b2e6a1946c48372c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T19:10:29.230523Z",
     "start_time": "2025-06-04T19:10:28.952576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_metrics(p):\n",
    "    predictions = np.argmax(p.predictions, axis=1)\n",
    "    return {\"accuracy\": accuracy_score(p.label_ids, predictions)}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TRAINING_ARGS,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_eval_dataset,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "id": "e57ac3d621ce0888",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training Model",
   "id": "149ed0f5f96caff6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T19:16:08.411578Z",
     "start_time": "2025-06-04T19:10:29.255963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nStarting model training...\")\n",
    "trainer.train()\n",
    "print(\"\\nTraining complete. Evaluating model on evaluation set...\")"
   ],
   "id": "b61b8a8f6e3fdc28",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting model training...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [147/147 05:36, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.666346</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.858000</td>\n",
       "      <td>1.309018</td>\n",
       "      <td>0.535354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.497800</td>\n",
       "      <td>1.074218</td>\n",
       "      <td>0.575758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete. Evaluating model on evaluation set...\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluating Model",
   "id": "a3b7929011ec0d11"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T19:16:23.983057Z",
     "start_time": "2025-06-04T19:16:08.777752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\"\\nEvaluation Results: {eval_results}\")\n",
    "\n",
    "predictions_output = trainer.predict(tokenized_eval_dataset)\n",
    "y_pred = np.argmax(predictions_output.predictions, axis=1)\n",
    "y_true = predictions_output.label_ids\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=LABELS))"
   ],
   "id": "dcd7b91346338d96",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Results: {'eval_loss': 1.0742179155349731, 'eval_accuracy': 0.5757575757575758, 'eval_runtime': 7.2771, 'eval_samples_per_second': 13.604, 'eval_steps_per_second': 1.786, 'epoch': 3.0}\n",
      "\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "             Anxiety       0.00      0.00      0.00         5\n",
      "             Bipolar       0.00      0.00      0.00         5\n",
      "              Stress       0.00      0.00      0.00         5\n",
      "          Depression       0.43      0.97      0.59        30\n",
      "              Normal       0.90      0.90      0.90        31\n",
      "Personality disorder       0.00      0.00      0.00         2\n",
      "            Suicidal       0.00      0.00      0.00        21\n",
      "\n",
      "            accuracy                           0.58        99\n",
      "           macro avg       0.19      0.27      0.21        99\n",
      "        weighted avg       0.41      0.58      0.46        99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jagman/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jagman/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jagman/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Inference with fine tune model",
   "id": "c7d4a8f9f17cf0a8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T19:16:24.372531Z",
     "start_time": "2025-06-04T19:16:23.994579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n--- Performing Inference with the Fine-tuned Model ---\")\n",
    "\n",
    "new_texts = [\n",
    "    \"I'm feeling incredibly anxious about my upcoming exam.\",\n",
    "    \"My mood swings have been uncontrollable lately, from ecstatic to rock bottom.\",\n",
    "    \"I'm exhausted and stressed out with all the deadlines.\",\n",
    "    \"I just want to stay in bed all day and not do anything.\",\n",
    "    \"Everything feels okay right now, just a normal day.\",\n",
    "    \"I sometimes feel like I'm not really myself, or my personality keeps changing.\",\n",
    "    \"I don't see any way out of this situation. I'm just done.\"\n",
    "]\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "print(\"\\nPredictions for new text data:\")\n",
    "for text in new_texts:\n",
    "    prediction = classifier(text)\n",
    "    predicted_label = prediction[0]['label']\n",
    "    score = prediction[0]['score']\n",
    "    print(f\"Text: '{text}'\")\n",
    "    print(f\"Predicted Category: {predicted_label} (Score: {score:.4f})\")\n",
    "    print(\"-\" * 50)"
   ],
   "id": "21e1894d1f7766d2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Performing Inference with the Fine-tuned Model ---\n",
      "\n",
      "Predictions for new text data:\n",
      "Text: 'I'm feeling incredibly anxious about my upcoming exam.'\n",
      "Predicted Category: Normal (Score: 0.6485)\n",
      "--------------------------------------------------\n",
      "Text: 'My mood swings have been uncontrollable lately, from ecstatic to rock bottom.'\n",
      "Predicted Category: Depression (Score: 0.4047)\n",
      "--------------------------------------------------\n",
      "Text: 'I'm exhausted and stressed out with all the deadlines.'\n",
      "Predicted Category: Normal (Score: 0.4862)\n",
      "--------------------------------------------------\n",
      "Text: 'I just want to stay in bed all day and not do anything.'\n",
      "Predicted Category: Depression (Score: 0.4287)\n",
      "--------------------------------------------------\n",
      "Text: 'Everything feels okay right now, just a normal day.'\n",
      "Predicted Category: Normal (Score: 0.3516)\n",
      "--------------------------------------------------\n",
      "Text: 'I sometimes feel like I'm not really myself, or my personality keeps changing.'\n",
      "Predicted Category: Depression (Score: 0.5092)\n",
      "--------------------------------------------------\n",
      "Text: 'I don't see any way out of this situation. I'm just done.'\n",
      "Predicted Category: Depression (Score: 0.3747)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Saving Model",
   "id": "72948029369b4106"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T19:16:24.814107Z",
     "start_time": "2025-06-04T19:16:24.416511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SAVE_FILE_NAME = \"./monke\"\n",
    "model.save_pretrained(SAVE_FILE_NAME)\n",
    "tokenizer.save_pretrained(SAVE_FILE_NAME)\n",
    "print(\"\\nFine-tuned model saved to \" + SAVE_FILE_NAME)\n"
   ],
   "id": "fc09ccefaad48e17",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine-tuned model saved to ./monke\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
