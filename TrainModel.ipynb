{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from transformers import pipeline\n",
    "\n",
    "# https://huggingface.co/mental/mental-roberta-base\n",
    "#or\n",
    "# https://huggingface.co/mental/mental-bert-base-uncased -- USED THIS\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "MODEL = \"mental/mental-bert-base-uncased\"\n",
    "# Uncomment this and command on line 5 in loading and preparing data\n",
    "#  SampleSize = 10000\n",
    "\n",
    "DATA_CSV_PATH = 'dataset/Combined Data 2.csv'\n",
    "\n",
    "TEXT_COLUMN = 'statement'\n",
    "LABEL_COLUMN = 'status'\n",
    "\n",
    "LABELS = ['Anxiety', 'Bipolar', 'Stress', 'Depression', 'Normal', 'Personality disorder', 'Suicidal']\n",
    "NUM_LABELS = len(LABELS)\n",
    "label_to_id = {label: i for i, label in enumerate(LABELS)}\n",
    "id_to_label = {i: label for i, label in enumerate(LABELS)}\n",
    "\n",
    "TRAINING_ARGS = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loading and Preparing Data\n",
   "id": "c2c1e983f1345f2f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"Loading data from: {DATA_CSV_PATH}\")\n",
    "df_data = pd.read_csv(DATA_CSV_PATH)\n",
    "# UNCOMMENT TO SET SPECIFIED SAMPLE SIZE\n",
    "# df_data = df_data.sample(SampleSize)\n",
    "print(\"Original DataFrame head:\")\n",
    "print(df_data.head())\n",
    "print(f\"Original DataFrame shape: {df_data.shape}\")\n",
    "\n",
    "df_data.dropna(subset=[TEXT_COLUMN, LABEL_COLUMN], inplace=True)\n",
    "df_data = df_data[df_data[LABEL_COLUMN].isin(LABELS)]\n",
    "df_data[TEXT_COLUMN] = df_data[TEXT_COLUMN].astype(str).str.strip()\n",
    "df_data = df_data[df_data[TEXT_COLUMN].str.len() > 0]\n",
    "\n",
    "\n",
    "print(f\"\\nDataFrame shape after cleaning: {df_data.shape}\")\n",
    "if df_data.empty:\n",
    "    print(\"Error: No data left after cleaning. Check your CSV and column names.\")\n",
    "    exit()\n",
    "\n",
    "df_data['labels'] = df_data[LABEL_COLUMN].map(label_to_id)\n",
    "if df_data['labels'].isnull().any():\n",
    "    print(\"Error: Some labels in your CSV did not match the defined LABELS. Check for typos.\")\n",
    "    print(\"Unique labels in CSV:\", df_data[LABEL_COLUMN].unique())\n",
    "    print(\"Defined LABELS:\", LABELS)\n",
    "    exit()\n",
    "\n",
    "train_df, eval_df = train_test_split(df_data, test_size=0.2, random_state=42, stratify=df_data['labels'])\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df[[TEXT_COLUMN, 'labels']])\n",
    "eval_dataset = Dataset.from_pandas(eval_df[[TEXT_COLUMN, 'labels']])\n",
    "\n",
    "print(f\"\\nTraining data samples: {len(train_dataset)}\")\n",
    "print(f\"Evaluation data samples: {len(eval_dataset)}\")\n",
    "print(\"First training example:\", train_dataset[0])"
   ],
   "id": "21607fb027bc4088",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tokenizer and Model for Fine-tuning\n",
   "id": "87feeaeef724bc9b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"\\nLoading tokenizer and model '{MODEL}' for fine-tuning...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL,\n",
    "    num_labels=NUM_LABELS,\n",
    "    id2label=id_to_label,\n",
    "    label2id=label_to_id\n",
    ")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[TEXT_COLUMN], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_eval_dataset = eval_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "tokenized_train_dataset.set_format(\"torch\", columns=['input_ids', 'attention_mask', 'labels'])\n",
    "tokenized_eval_dataset.set_format(\"torch\", columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "if '__index_level_0__' in tokenized_train_dataset.column_names:\n",
    "    tokenized_train_dataset = tokenized_train_dataset.remove_columns(['__index_level_0__'])\n",
    "if '__index_level_0__' in tokenized_eval_dataset.column_names:\n",
    "    tokenized_eval_dataset = tokenized_eval_dataset.remove_columns(['__index_level_0__'])\n"
   ],
   "id": "9b7e1ab382d15fd5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Metrics and Trainer",
   "id": "b2e6a1946c48372c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compute_metrics(p):\n",
    "    predictions = np.argmax(p.predictions, axis=1)\n",
    "    return {\"accuracy\": accuracy_score(p.label_ids, predictions)}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TRAINING_ARGS,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_eval_dataset,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "id": "e57ac3d621ce0888",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training Model",
   "id": "149ed0f5f96caff6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\nStarting model training...\")\n",
    "trainer.train()\n",
    "print(\"\\nTraining complete. Evaluating model on evaluation set...\")"
   ],
   "id": "b61b8a8f6e3fdc28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluating Model",
   "id": "a3b7929011ec0d11"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\"\\nEvaluation Results: {eval_results}\")\n",
    "\n",
    "predictions_output = trainer.predict(tokenized_eval_dataset)\n",
    "y_pred = np.argmax(predictions_output.predictions, axis=1)\n",
    "y_true = predictions_output.label_ids\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=LABELS))"
   ],
   "id": "dcd7b91346338d96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Inference with fine tune model",
   "id": "c7d4a8f9f17cf0a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n--- Performing Inference with the Fine-tuned Model ---\")\n",
    "\n",
    "new_texts = [\n",
    "    \"I'm feeling incredibly anxious about my upcoming exam.\",\n",
    "    \"My mood swings have been uncontrollable lately, from ecstatic to rock bottom.\",\n",
    "    \"I'm exhausted and stressed out with all the deadlines.\",\n",
    "    \"I just want to stay in bed all day and not do anything.\",\n",
    "    \"Everything feels okay right now, just a normal day.\",\n",
    "    \"I sometimes feel like I'm not really myself, or my personality keeps changing.\",\n",
    "    \"I don't see any way out of this situation. I'm just done.\"\n",
    "]\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "print(\"\\nPredictions for new text data:\")\n",
    "for text in new_texts:\n",
    "    prediction = classifier(text)\n",
    "    predicted_label = prediction[0]['label']\n",
    "    score = prediction[0]['score']\n",
    "    print(f\"Text: '{text}'\")\n",
    "    print(f\"Predicted Category: {predicted_label} (Score: {score:.4f})\")\n",
    "    print(\"-\" * 50)"
   ],
   "id": "21e1894d1f7766d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Saving Model",
   "id": "72948029369b4106"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "SAVE_FILE_NAME = \"./monke\"\n",
    "model.save_pretrained(SAVE_FILE_NAME)\n",
    "tokenizer.save_pretrained(SAVE_FILE_NAME)\n",
    "print(\"\\nFine-tuned model saved to \" + SAVE_FILE_NAME)\n"
   ],
   "id": "fc09ccefaad48e17",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
