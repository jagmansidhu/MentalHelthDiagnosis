{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-05T20:14:56.731383Z",
     "start_time": "2025-06-05T20:14:56.676532Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from transformers import pipeline\n",
    "\n",
    "# https://huggingface.co/mental/mental-roberta-base\n",
    "#or\n",
    "# https://huggingface.co/mental/mental-bert-base-uncased -- USED THIS\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "MODEL = \"mental/mental-bert-base-uncased\"\n",
    "# Uncomment this and command on line 5 in loading and preparing data\n",
    "#  SampleSize = 10000\n",
    "\n",
    "DATA_CSV_PATH = 'dataset/Combined Data 2.csv'\n",
    "\n",
    "TEXT_COLUMN = 'statement'\n",
    "LABEL_COLUMN = 'status'\n",
    "\n",
    "LABELS = ['Anxiety', 'Bipolar', 'Stress', 'Depression', 'Normal', 'Personality disorder', 'Suicidal']\n",
    "NUM_LABELS = len(LABELS)\n",
    "label_to_id = {label: i for i, label in enumerate(LABELS)}\n",
    "id_to_label = {i: label for i, label in enumerate(LABELS)}\n",
    "\n",
    "TRAINING_ARGS = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loading and Preparing Data\n",
   "id": "c2c1e983f1345f2f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T20:14:57.157648Z",
     "start_time": "2025-06-05T20:14:56.735687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Loading data from: {DATA_CSV_PATH}\")\n",
    "df_data = pd.read_csv(DATA_CSV_PATH)\n",
    "# UNCOMMENT TO SET SPECIFIED SAMPLE SIZE\n",
    "# df_data = df_data.sample(SampleSize)\n",
    "print(\"Original DataFrame head:\")\n",
    "print(df_data.head())\n",
    "print(f\"Original DataFrame shape: {df_data.shape}\")\n",
    "\n",
    "df_data.dropna(subset=[TEXT_COLUMN, LABEL_COLUMN], inplace=True)\n",
    "df_data = df_data[df_data[LABEL_COLUMN].isin(LABELS)]\n",
    "df_data[TEXT_COLUMN] = df_data[TEXT_COLUMN].astype(str).str.strip()\n",
    "df_data = df_data[df_data[TEXT_COLUMN].str.len() > 0]\n",
    "\n",
    "\n",
    "print(f\"\\nDataFrame shape after cleaning: {df_data.shape}\")\n",
    "if df_data.empty:\n",
    "    print(\"Error: No data left after cleaning. Check your CSV and column names.\")\n",
    "    exit()\n",
    "\n",
    "df_data['labels'] = df_data[LABEL_COLUMN].map(label_to_id)\n",
    "if df_data['labels'].isnull().any():\n",
    "    print(\"Error: Some labels in your CSV did not match the defined LABELS. Check for typos.\")\n",
    "    print(\"Unique labels in CSV:\", df_data[LABEL_COLUMN].unique())\n",
    "    print(\"Defined LABELS:\", LABELS)\n",
    "    exit()\n",
    "\n",
    "train_df, eval_df = train_test_split(df_data, test_size=0.2, random_state=42, stratify=df_data['labels'])\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df[[TEXT_COLUMN, 'labels']])\n",
    "eval_dataset = Dataset.from_pandas(eval_df[[TEXT_COLUMN, 'labels']])\n",
    "\n",
    "print(f\"\\nTraining data samples: {len(train_dataset)}\")\n",
    "print(f\"Evaluation data samples: {len(eval_dataset)}\")\n",
    "print(\"First training example:\", train_dataset[0])"
   ],
   "id": "21607fb027bc4088",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: dataset/Combined Data 2.csv\n",
      "Original DataFrame head:\n",
      "       Unnamed: 0                                          statement  \\\n",
      "22261       22261  Just as the the title says. I feel like one is...   \n",
      "41400       41400  a blackened sky encroached tugging behind it m...   \n",
      "20065       20065  It gives you insomnia, which in turn makes you...   \n",
      "30036       30036  Hello all, I'm a new submitter to this channel...   \n",
      "780           780                   Thank God the CB is over for Eid   \n",
      "\n",
      "           status  \n",
      "22261  Depression  \n",
      "41400  Depression  \n",
      "20065  Depression  \n",
      "30036      Normal  \n",
      "780        Normal  \n",
      "Original DataFrame shape: (10000, 3)\n",
      "\n",
      "DataFrame shape after cleaning: (9919, 3)\n",
      "\n",
      "Training data samples: 7935\n",
      "Evaluation data samples: 1984\n",
      "First training example: {'statement': 'i like this restaurant because they give you free bread.', 'labels': 4, '__index_level_0__': 32571}\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tokenizer and Model for Fine-tuning\n",
   "id": "87feeaeef724bc9b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T20:14:59.388487Z",
     "start_time": "2025-06-05T20:14:57.189105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"\\nLoading tokenizer and model '{MODEL}' for fine-tuning...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL,\n",
    "    num_labels=NUM_LABELS,\n",
    "    id2label=id_to_label,\n",
    "    label2id=label_to_id\n",
    ")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[TEXT_COLUMN], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_eval_dataset = eval_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "tokenized_train_dataset.set_format(\"torch\", columns=['input_ids', 'attention_mask', 'labels'])\n",
    "tokenized_eval_dataset.set_format(\"torch\", columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "if '__index_level_0__' in tokenized_train_dataset.column_names:\n",
    "    tokenized_train_dataset = tokenized_train_dataset.remove_columns(['__index_level_0__'])\n",
    "if '__index_level_0__' in tokenized_eval_dataset.column_names:\n",
    "    tokenized_eval_dataset = tokenized_eval_dataset.remove_columns(['__index_level_0__'])\n"
   ],
   "id": "9b7e1ab382d15fd5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading tokenizer and model 'mental/mental-bert-base-uncased' for fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at mental/mental-bert-base-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/7935 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7a0e0c5450a045c1b287bb19430f1647"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1984 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cc98c43f240c4168bfb5bbcb123afdd6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Metrics and Trainer",
   "id": "b2e6a1946c48372c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T20:15:11.432346Z",
     "start_time": "2025-06-05T20:14:59.398938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_metrics(p):\n",
    "    predictions = np.argmax(p.predictions, axis=1)\n",
    "    return {\"accuracy\": accuracy_score(p.label_ids, predictions)}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TRAINING_ARGS,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_eval_dataset,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "id": "e57ac3d621ce0888",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training Model",
   "id": "149ed0f5f96caff6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T20:15:27.848076Z",
     "start_time": "2025-06-05T20:15:11.447307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nStarting model training...\")\n",
    "trainer.train()\n",
    "print(\"\\nTraining complete. Evaluating model on evaluation set...\")"
   ],
   "id": "b61b8a8f6e3fdc28",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting model training...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='2976' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   9/2976 00:11 < 1:24:25, 0.59 it/s, Epoch 0.01/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mStarting model training...\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mTraining complete. Evaluating model on evaluation set...\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/transformers/trainer.py:2240\u001B[39m, in \u001B[36mTrainer.train\u001B[39m\u001B[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[39m\n\u001B[32m   2238\u001B[39m         hf_hub_utils.enable_progress_bars()\n\u001B[32m   2239\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2240\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2241\u001B[39m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m=\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2242\u001B[39m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2243\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2244\u001B[39m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2245\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/transformers/trainer.py:2606\u001B[39m, in \u001B[36mTrainer._inner_training_loop\u001B[39m\u001B[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[39m\n\u001B[32m   2602\u001B[39m         grad_norm = _grad_norm\n\u001B[32m   2604\u001B[39m \u001B[38;5;28mself\u001B[39m.control = \u001B[38;5;28mself\u001B[39m.callback_handler.on_pre_optimizer_step(args, \u001B[38;5;28mself\u001B[39m.state, \u001B[38;5;28mself\u001B[39m.control)\n\u001B[32m-> \u001B[39m\u001B[32m2606\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2608\u001B[39m \u001B[38;5;28mself\u001B[39m.control = \u001B[38;5;28mself\u001B[39m.callback_handler.on_optimizer_step(args, \u001B[38;5;28mself\u001B[39m.state, \u001B[38;5;28mself\u001B[39m.control)\n\u001B[32m   2610\u001B[39m \u001B[38;5;66;03m# get leaning rate before update\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/accelerate/optimizer.py:179\u001B[39m, in \u001B[36mAcceleratedOptimizer.step\u001B[39m\u001B[34m(self, closure)\u001B[39m\n\u001B[32m    177\u001B[39m         \u001B[38;5;28mself\u001B[39m._accelerate_step_called = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m    178\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m179\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclosure\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    180\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.accelerator_state.distributed_type == DistributedType.XLA:\n\u001B[32m    181\u001B[39m     \u001B[38;5;28mself\u001B[39m.gradient_state.is_xla_gradients_synced = \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:140\u001B[39m, in \u001B[36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    138\u001B[39m opt = opt_ref()\n\u001B[32m    139\u001B[39m opt._opt_called = \u001B[38;5;28;01mTrue\u001B[39;00m  \u001B[38;5;66;03m# type: ignore[union-attr]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m140\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__get__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mopt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopt\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__class__\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/optim/optimizer.py:493\u001B[39m, in \u001B[36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    488\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    489\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[32m    490\u001B[39m                 \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    491\u001B[39m             )\n\u001B[32m--> \u001B[39m\u001B[32m493\u001B[39m out = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    494\u001B[39m \u001B[38;5;28mself\u001B[39m._optimizer_step_code()\n\u001B[32m    496\u001B[39m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/optim/optimizer.py:91\u001B[39m, in \u001B[36m_use_grad_for_differentiable.<locals>._use_grad\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m     89\u001B[39m     torch.set_grad_enabled(\u001B[38;5;28mself\u001B[39m.defaults[\u001B[33m\"\u001B[39m\u001B[33mdifferentiable\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m     90\u001B[39m     torch._dynamo.graph_break()\n\u001B[32m---> \u001B[39m\u001B[32m91\u001B[39m     ret = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     92\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m     93\u001B[39m     torch._dynamo.graph_break()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/optim/adamw.py:243\u001B[39m, in \u001B[36mAdamW.step\u001B[39m\u001B[34m(self, closure)\u001B[39m\n\u001B[32m    230\u001B[39m     beta1, beta2 = cast(Tuple[\u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;28mfloat\u001B[39m], group[\u001B[33m\"\u001B[39m\u001B[33mbetas\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m    232\u001B[39m     has_complex = \u001B[38;5;28mself\u001B[39m._init_group(\n\u001B[32m    233\u001B[39m         group,\n\u001B[32m    234\u001B[39m         params_with_grad,\n\u001B[32m   (...)\u001B[39m\u001B[32m    240\u001B[39m         state_steps,\n\u001B[32m    241\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m243\u001B[39m     \u001B[43madamw\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    244\u001B[39m \u001B[43m        \u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    245\u001B[39m \u001B[43m        \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    246\u001B[39m \u001B[43m        \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    247\u001B[39m \u001B[43m        \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    248\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    249\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    250\u001B[39m \u001B[43m        \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[43m=\u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    251\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    252\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    253\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlr\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mlr\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    254\u001B[39m \u001B[43m        \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mweight_decay\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    255\u001B[39m \u001B[43m        \u001B[49m\u001B[43meps\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43meps\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    256\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmaximize\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    257\u001B[39m \u001B[43m        \u001B[49m\u001B[43mforeach\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mforeach\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    258\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcapturable\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    259\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mdifferentiable\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    260\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfused\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfused\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    261\u001B[39m \u001B[43m        \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mgrad_scale\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    262\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfound_inf\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    263\u001B[39m \u001B[43m        \u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    264\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    266\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/optim/optimizer.py:154\u001B[39m, in \u001B[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    152\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m disabled_func(*args, **kwargs)\n\u001B[32m    153\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m154\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/optim/adamw.py:875\u001B[39m, in \u001B[36madamw\u001B[39m\u001B[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[39m\n\u001B[32m    872\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    873\u001B[39m     func = _single_tensor_adamw\n\u001B[32m--> \u001B[39m\u001B[32m875\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    876\u001B[39m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    877\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    878\u001B[39m \u001B[43m    \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    879\u001B[39m \u001B[43m    \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    880\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    881\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    882\u001B[39m \u001B[43m    \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[43m=\u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    883\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    884\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    885\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlr\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    886\u001B[39m \u001B[43m    \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[43m=\u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    887\u001B[39m \u001B[43m    \u001B[49m\u001B[43meps\u001B[49m\u001B[43m=\u001B[49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    888\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    889\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcapturable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    890\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    891\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    892\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    893\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    894\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/optim/adamw.py:477\u001B[39m, in \u001B[36m_single_tensor_adamw\u001B[39m\u001B[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001B[39m\n\u001B[32m    475\u001B[39m         denom = (max_exp_avg_sqs[i].sqrt() / bias_correction2_sqrt).add_(eps)\n\u001B[32m    476\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m477\u001B[39m         denom = (\u001B[43mexp_avg_sq\u001B[49m\u001B[43m.\u001B[49m\u001B[43msqrt\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m / bias_correction2_sqrt).add_(eps)\n\u001B[32m    479\u001B[39m     param.addcdiv_(exp_avg, denom, value=-step_size)\n\u001B[32m    481\u001B[39m \u001B[38;5;66;03m# Lastly, switch back to complex view\u001B[39;00m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluating Model",
   "id": "a3b7929011ec0d11"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T20:15:27.879999Z",
     "start_time": "2025-06-04T19:16:08.777752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\"\\nEvaluation Results: {eval_results}\")\n",
    "\n",
    "predictions_output = trainer.predict(tokenized_eval_dataset)\n",
    "y_pred = np.argmax(predictions_output.predictions, axis=1)\n",
    "y_true = predictions_output.label_ids\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=LABELS))"
   ],
   "id": "dcd7b91346338d96",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Results: {'eval_loss': 1.0742179155349731, 'eval_accuracy': 0.5757575757575758, 'eval_runtime': 7.2771, 'eval_samples_per_second': 13.604, 'eval_steps_per_second': 1.786, 'epoch': 3.0}\n",
      "\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "             Anxiety       0.00      0.00      0.00         5\n",
      "             Bipolar       0.00      0.00      0.00         5\n",
      "              Stress       0.00      0.00      0.00         5\n",
      "          Depression       0.43      0.97      0.59        30\n",
      "              Normal       0.90      0.90      0.90        31\n",
      "Personality disorder       0.00      0.00      0.00         2\n",
      "            Suicidal       0.00      0.00      0.00        21\n",
      "\n",
      "            accuracy                           0.58        99\n",
      "           macro avg       0.19      0.27      0.21        99\n",
      "        weighted avg       0.41      0.58      0.46        99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jagman/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jagman/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jagman/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Inference with fine tune model",
   "id": "c7d4a8f9f17cf0a8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T20:15:27.890065Z",
     "start_time": "2025-06-04T19:16:23.994579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n--- Performing Inference with the Fine-tuned Model ---\")\n",
    "\n",
    "new_texts = [\n",
    "    \"I'm feeling incredibly anxious about my upcoming exam.\",\n",
    "    \"My mood swings have been uncontrollable lately, from ecstatic to rock bottom.\",\n",
    "    \"I'm exhausted and stressed out with all the deadlines.\",\n",
    "    \"I just want to stay in bed all day and not do anything.\",\n",
    "    \"Everything feels okay right now, just a normal day.\",\n",
    "    \"I sometimes feel like I'm not really myself, or my personality keeps changing.\",\n",
    "    \"I don't see any way out of this situation. I'm just done.\"\n",
    "]\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "print(\"\\nPredictions for new text data:\")\n",
    "for text in new_texts:\n",
    "    prediction = classifier(text)\n",
    "    predicted_label = prediction[0]['label']\n",
    "    score = prediction[0]['score']\n",
    "    print(f\"Text: '{text}'\")\n",
    "    print(f\"Predicted Category: {predicted_label} (Score: {score:.4f})\")\n",
    "    print(\"-\" * 50)"
   ],
   "id": "21e1894d1f7766d2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Performing Inference with the Fine-tuned Model ---\n",
      "\n",
      "Predictions for new text data:\n",
      "Text: 'I'm feeling incredibly anxious about my upcoming exam.'\n",
      "Predicted Category: Normal (Score: 0.6485)\n",
      "--------------------------------------------------\n",
      "Text: 'My mood swings have been uncontrollable lately, from ecstatic to rock bottom.'\n",
      "Predicted Category: Depression (Score: 0.4047)\n",
      "--------------------------------------------------\n",
      "Text: 'I'm exhausted and stressed out with all the deadlines.'\n",
      "Predicted Category: Normal (Score: 0.4862)\n",
      "--------------------------------------------------\n",
      "Text: 'I just want to stay in bed all day and not do anything.'\n",
      "Predicted Category: Depression (Score: 0.4287)\n",
      "--------------------------------------------------\n",
      "Text: 'Everything feels okay right now, just a normal day.'\n",
      "Predicted Category: Normal (Score: 0.3516)\n",
      "--------------------------------------------------\n",
      "Text: 'I sometimes feel like I'm not really myself, or my personality keeps changing.'\n",
      "Predicted Category: Depression (Score: 0.5092)\n",
      "--------------------------------------------------\n",
      "Text: 'I don't see any way out of this situation. I'm just done.'\n",
      "Predicted Category: Depression (Score: 0.3747)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Saving Model",
   "id": "72948029369b4106"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T20:15:27.890638Z",
     "start_time": "2025-06-04T19:16:24.416511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SAVE_FILE_NAME = \"./monke\"\n",
    "model.save_pretrained(SAVE_FILE_NAME)\n",
    "tokenizer.save_pretrained(SAVE_FILE_NAME)\n",
    "print(\"\\nFine-tuned model saved to \" + SAVE_FILE_NAME)\n"
   ],
   "id": "fc09ccefaad48e17",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine-tuned model saved to ./monke\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
